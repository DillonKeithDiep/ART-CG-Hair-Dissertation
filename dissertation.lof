\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces A point cloud representation is a collection of points (vertices) that describe surface geometry. Range images map pixels of a depth image to a set of points in the scene. Voxels are unit cubes, corresponding to the concept of pixels, a collection of voxels describe an object volumetrically.}}{1}{figure.1.1}
\contentsline {figure}{\numberline {1.2}{\ignorespaces Image of hair geometry.}}{2}{figure.1.2}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces In a latent variable model, a latent variable, $\bm {X}$, is input into a function, $\bm {F}$, which maps to the output observed variables, $\bm {Y}$.}}{9}{figure.2.1}
\contentsline {figure}{\numberline {2.2}{\ignorespaces To the left is a prior distribution of a Gaussian process, and to the right is the posterior distribution after updating with observations that are corrupted by noise. The semi-transparent functions represent samples from the likelihood distribution.}}{12}{figure.2.2}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces examples of polygon hair mesh training data.}}{17}{figure.3.1}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Triangular faces are highlighted using a selection procedure for all faces that are made of exactly three edges. To the left is an original mesh acquired, the middle shows a selection of remaining triangles after the automatic tri-to-quad conversion, and the right displays a retopologised mesh of entirely quads.}}{18}{figure.3.2}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Source: \href {https://commons.wikimedia.org/wiki/File:3D_Spherical.svg}{https://commons.wikimedia.org/wiki/File:3D\_Spherical.svg}, Public Domain. The 3D spherical coordinate system.}}{19}{figure.3.3}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Sphere meshes visualise root positions. The angle ranges specify coverage area of the scalp, while the interval of placements determines resolution. Fitting a sphere to the reference head mesh approximates the radial distance and origin.}}{19}{figure.3.4}
\contentsline {figure}{\numberline {3.5}{\ignorespaces A possible configuration of 10260 data points in the generative model}}{20}{figure.3.5}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Our edge loop extraction algorithm begins by selecting an edge within the mesh graph. The two vertices of the edge are \textbf {end vertices}. We then proceed to \textit {grow} the edge loop selection. Take the set of \textbf {first degree neighbours} of the \textit {end vertices}, these nodes are the \textit {candidates} for the edge loop. We remove edges that are part of the current edge loop from this set of first degree neighbours. We add the first degree neighbours to a set of face vertices for following iterations. Take the neighbours of the first degree neighbours as a set of \textbf {second degree neighbours}, removing its originating end vertex. A candidate node is only accepted to the edge loop if its set neighbours do not intersect with the set of face vertices. Accepted vertices are appended to the list of end vertices, this process is repeated until there are no end vertices left to grow the selection.}}{21}{figure.3.6}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Observe that the corner vertices have two edges, and the boundary edges have three. Determining the root edge loop is done by choosing the boundary edge loop that is closest to the scalp surface.}}{22}{figure.3.7}
\contentsline {figure}{\numberline {3.8}{\ignorespaces Source: \href {http://gpytest2.readthedocs.io/en/latest/tuto_kernel_overview.html}{GPy Library Documentation: A kernel overview}. The GPy library offers various standard kernels. Multi-modal kernels can be formed from combining kernels to represent data of complex nature.}}{25}{figure.3.8}
\contentsline {figure}{\numberline {3.9}{\ignorespaces As expected, a linearly embedded hairstyle is of little use as it can only extrapolate along one style. }}{25}{figure.3.9}
\contentsline {figure}{\numberline {3.10}{\ignorespaces The latent hair modelling add-on for Blender 3D uses the image editor to display the latent manifold.}}{26}{figure.3.10}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Images presented in the survey, named mesh 1-4 on the first row from left to right, and 5-8 on the second. Training meshes are 1, 4, 5, and 6. Output mesh are 2, 3, 7, and 8.}}{27}{figure.4.1}
\contentsline {figure}{\numberline {4.2}{\ignorespaces The mean, standard deviation, and variance comparison of training and output mesh presented on the survey.}}{28}{figure.4.2}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Responses for difficulty rating of generating output with a latent manifold, from 1 (easy) to 10 (difficult).}}{29}{figure.4.3}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Responses for estimation of automating the 3D production pipeline with a latent manifold, from 1 (none) to 10 (all).}}{29}{figure.4.4}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Responses for whether participants would use a latent manifold for rapid prototyping.}}{30}{figure.4.5}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Results of a participant who located later targets quickly after spending some time to explore the manifold first.}}{31}{figure.4.6}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Plot for the first three tests of a participant.}}{31}{figure.4.7}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Plot for the first three tests of a participant.}}{32}{figure.4.8}
\addvspace {10\p@ }
\addvspace {10\p@ }
