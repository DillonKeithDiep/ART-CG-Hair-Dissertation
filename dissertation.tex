% The document class supplies options to control rendering of some standard
% features in the result.  The goal is for uniform style, so some attention 
% to detail is *vital* with all fields.  Each field (i.e., text inside the
% curly braces below, so the MEng text inside {MEng} for instance) should 
% take into account the following:
%
% - author name       should be formatted as "FirstName LastName"
%   (not "Initial LastName" for example),
% - supervisor name   should be formatted as "Title FirstName LastName"
%   (where Title is "Dr." or "Prof." for example),
% - degree programme  should be "BSc", "MEng", "MSci", "MSc" or "PhD",
% - dissertation title should be correctly capitalised (plus you can have
%   an optional sub-title if appropriate, or leave this field blank),
% - dissertation type should be formatted as one of the following:
%   * for the MEng degree programme either "enterprise" or "research" to
%     reflect the stream,
%   * for the MSc  degree programme "$X/Y/Z$" for a project deemed to be
%     X%, Y% and Z% of type I, II and III.
% - year              should be formatted as a 4-digit year of submission
%   (so 2014 rather than the accademic year, say 2013/14 say).

\documentclass[ % the name of the author
author={Dillon Keith Diep [INCOMPLETE DRAFT, NOT FOR SUBMISSION]},
% the name of the supervisor
supervisor={Dr. Carl Henrik Ek},
% the degree programme
degree={MEng},
% the dissertation    title (which cannot be blank)
title={ARt-CG:},
% the dissertation subtitle (which can    be blank)
subtitle={Assisted Real-time Content Generation of 3D Hair by Learning Manifolds},
% the dissertation     type
type={Research},
% the year of submission
year={2014} ]{dissertation}
\begin{document}
% =============================================================================

% This section simply introduces the structural guidelines.  It can clearly
% be deleted (or commented out) if you use the file as a template for your
% own dissertation: everything following it is in the correct order to use 
% as is.

% =============================================================================

% This macro creates the standard UoB title page by using information drawn
% from the document class (meaning it is vital you select the correct degree 
% title and so on).

\maketitle

% After the title page (which is a special case in that it is not numbered)
% comes the front matter or preliminaries; this macro signals the start of
% such content, meaning the pages are numbered with Roman numerals.

\frontmatter

% This macro creates the standard UoB declaration; on the printed hard-copy,
% this must be physically signed by the author in the space indicated.

\makedecl

% LaTeX automatically generates a table of contents, plus associated lists 
% of figures, tables and algorithms.  The former is a compulsory part of the
% dissertation, but if you do not require the latter they can be suppressed
% by simply commenting out the associated macro.

\tableofcontents
\listoffigures
\listoftables
\listofalgorithms
\lstlistoflistings

% The following sections are part of the front matter, but are not generated
% automatically by LaTeX; the use of \chapter* means they are not numbered.

% -----------------------------------------------------------------------------

\chapter*{Executive Summary}

{\bf A compulsory section, of at most $1$ page} 
\vspace{1cm} 

\noindent
The topic of this thesis explores assisted content generation by training generative models using unsupervised machine learning for the production of 3D hair geometry. The research hypothesis of this study is that non-linear probabilistic principal component analysis with the Gaussian Process Latent Variable Model is applicable for improving the creative production workflow of complex 3D hair geometry for humanoids.

Production of 3D virtual worlds is a time-consuming and costly process that also demand expert knowledge. 3D assets encompass a vast range of applications, ranging from simulations and research, to contributing towards the functioning of many businesses. The production of 3D assets impacts many industries including engineering, medicine, and the provisioning of entertainment. One particular task is the creation of 3D hair geometry for humanoid characters. The production of 3D hair is arduous as hair structure is a complex system containing much interdependence between components.

Machine learning applications typically use large data sets for training on problems that often have a concise answer for a given prediction. The application of machine learning to enhance production for creative work is an exciting field that tackles novel challenges: artistic products tend to have small sets of data available, and evaluation of quality is subjective. Given the same input, acceptable solutions can vary significantly. The mentioned peculiarities of applying machine learning for 3D mesh data establish a unique field of problems to investigate.

Existing tools for 3D modelling have remained mostly static in the paradigm of approach over the past several decades. Automation through methods such as procedural generation can produce output much faster, but the lack of control over the final result makes it less desirable than traditional methods of 3D modelling. The focus of this project is to formulate a revolutionary approach that improves the workflow of producing 3D hair geometry through unsupervised training of generative models.

\begin{quote}
	\noindent
	\begin{itemize}
		\item Formulation of a generative model for 3D humanoid hair structure
		\item Resolving the alignment problem by approximating raw input data using a generative model
		\item Learning a low dimension latent-space of high dimensional hair structure data
		{\color{red}
			\item Evaluated the performance of various kernels for high dimensional training data
			\item Formulation of reparation techniques on output generation of 3D geometry to conform with established constraints
		}
		\item Implemented an add-on package for a 3D production program, Blender
		\begin{itemize}
			\item The implementation creates guiding splines that are useful for generating hair geometry
			\item Appropriate for small training set that is practical for content creators
			\item Real-time performance that matches state of the art non-learning tools
		\end{itemize}
	\end{itemize}
\end{quote}

% -----------------------------------------------------------------------------

\chapter*{Supporting Technologies}

{\bf A compulsory section, of at most $1$ page}
\vspace{1cm} 

\noindent
This section should present a detailed summary, in bullet point form, 
of any third-party resources (e.g., hardware and software components) 
used during the project.  Use of such resources is always perfectly 
acceptable: the goal of this section is simply to be clear about how
and where they are used, so that a clear assessment of your work can
result.  The content can focus on the project topic itself (rather,
for example, than including ``I used \mbox{\LaTeX} to prepare my 
dissertation''); an example is as follows:

\begin{quote}
	\noindent
	\begin{itemize}
		\item I used the Java {\tt BigInteger} class to support my implementation 
		of RSA.
		\item I used a parts of the OpenCV computer vision library to capture 
		images from a camera, and for various standard operations (e.g., 
		threshold, edge detection).
		\item I used an FPGA device supplied by the Department, and altered it 
		to support an open-source UART core obtained from 
		\url{http://opencores.org/}.
		\item The web-interface component of my system was implemented by 
		extending the open-source WordPress software available from
		\url{http://wordpress.org/}.
	\end{itemize}
\end{quote}

% -----------------------------------------------------------------------------

\chapter*{Notation and Acronyms}

{\bf An optional section, of roughly $1$ or $2$ pages}
\vspace{1cm} 

\noindent
Any well written document will introduce notation and acronyms before
their use, {\em even if} they are standard in some way: this ensures 
any reader can understand the resulting self-contained content.  

Said introduction can exist within the dissertation itself, wherever 
that is appropriate.  For an acronym, this is typically achieved at 
the first point of use via ``Advanced Encryption Standard (AES)'' or 
similar, noting the capitalisation of relevant letters.  However, it 
can be useful to include an additional, dedicated list at the start 
of the dissertation; the advantage of doing so is that you cannot 
mistakenly use an acronym before defining it.  A limited example is 
as follows:

\begin{quote}
	\noindent
	\begin{tabular}{lcl}
		AES                 &:     & Advanced Encryption Standard                                         \\
		DES                 &:     & Data Encryption Standard                                             \\
		&\vdots&                                                                      \\
		${\mathcal H}( x )$ &:     & the Hamming weight of $x$                                            \\
		${\mathbb  F}_q$    &:     & a finite field with $q$ elements                                     \\
		$x_i$               &:     & the $i$-th bit of some binary sequence $x$, st. $x_i \in \{ 0, 1 \}$ \\
	\end{tabular}
\end{quote}

% -----------------------------------------------------------------------------

\chapter*{Acknowledgements}

{\bf An optional section, of at most $1$ page}
\vspace{1cm} 

\noindent
It is common practice (although totally optional) to acknowledge any
third-party advice, contribution or influence you have found useful
during your work.  Examples include support from friends or family, 
the input of your Supervisor and/or Advisor, external organisations 
or persons who  have supplied resources of some kind (e.g., funding, 
advice or time), and so on.

% =============================================================================

% After the front matter comes a number of chapters; under each chapter,
% sections, subsections and even subsubsections are permissible.  The
% pages in this part are numbered with Arabic numerals.  Note that:
%
% - A reference point can be marked using \label{XXX}, and then later
%   referred to via \ref{XXX}; for example Chapter\ref{chap:context}.
% - The chapters are presented here in one file; this can become hard
%   to manage.  An alternative is to save the content in seprate files
%   the use \input{XXX} to import it, which acts like the #include
%   directive in C.

\mainmatter

% -----------------------------------------------------------------------------

\chapter{Contextual Background}
\label{chap:context}

\section{Production of 3D Content}
In computer graphics, 3D objects are represented in many forms. 3D scanners capture raw data in various forms such as point clouds, range images, and voxels. A point cloud is simply a collection of points, often used in computer vision to sample surface geometry.  Range images map pixels of a depth image to a set of points in the scene. A voxel is a unit cube, corresponding to a pixel, a collection of voxels define the volume of an object. Voxels have applications in many fields, including visualisation of medical data. \cite{mri}

In a production environment it is straightforward to define geometry as opposed to capturing examples. The most common representation used for CG production are polygonal meshes, data that contains information of vertices, edges, and faces. The topology of a mesh is the organisation of components that define the geometry. Two surfaces with the same appearance could have different topology, affecting how well the meshes could deform and react to operations. Where precision is concerned, parametric definitions such as NURBS (Non-uniform rational basis spline) are preferred as mathematical models are exact. Each representation has its advantages depending on the use case. It is possible to convert between representations, but data loss may be incurred. Properties that make polygon meshes desirable include efficient rendering, simple to define, expressive enough to capture geometry required, and works well with established techniques such as UV texture mapping and a plethora of mesh-based algorithms. The rendering pipeline often converts meshes to tri-faces (faces constructed by three edges) as an optimisation process, but best practice for 3D artists is to maintain a topology of quad-faces which are easier to organise and conforms better with editing tools and algorithms.

\subsection{3D Hair Geometry}
On average, a human is born with between 90,000 to 150,000 scalp hair follicles. \cite{hairfollicles} It is computationally very expensive to render and animate physically correct hair, but creative liberties have been taken to approximate, or stylize 3D hair such that it is both acceptable aesthetically and feasible in terms of performance. This study considers modelling of hair geometry, the motion of hair is assumed to be its default resting pose.

In recent years, impressive 3D hair solutions for real-time simulation of realistic hair and fur, such as \textit{NVIDIA HairWorks} and \textit{AMD TressFX} has emerged. These solutions, however, have limited application in comparison to their traditional counterpart of polygonal hair. It is often the case that texture-mapped polygonal hair is used as a fallback when advanced simulation fails. Realism is not necessarily always desirable, polygon hair can flexibly represent different art styles. In some cases, a blend of multiple representations are used to balance between cost and quality. 3D hair in cinematography with large budget can afford to render hair with much higher fidelity for important characters, but would still consider use efficient variants for scenarios such as crowd simulation. Ultimately, it can be observed that the representation of virtual hair generally follows a structure of splines with control points that define the overall organisation of strands or segments.


\begin{figure}[!h]
	\centering
	To add %*
	\caption{Image of hair geometry.}
	\label{fig}
\end{figure}

\subsection{Procedural Generation and Automated Production}
Procedural generation techniques produce output that adhere to rules established by the generative model defined. Such techniques have been successfully applied for generation of terrains and city modelling. \cite{procedural1} Fractals and methods such as the Lindenmayer system has been used to produce patterns that resemble those observed in nature. \cite{lsystem} Automated techniques such as the ones discussed, however, are seldom used for modelling important objects with specific design. It is difficult to control the output of procedurally generated content without heavily restricting its capabilities. Automated methods that do not learn is cannot adapt to changing demands without reimplementation.

\section{Motivation and Significance}
State of the art 3D production software such as AutoDesk Maya, 3DS Max, and Blender are advanced programs with sophisticated list of features. That said, such programs have extremely convoluted user interfaces, even the most experienced professionals do not recognise each and every tool available. The most versatile tools are generally the most basic that perform atomic changes as they are applicable in every scenario. Examples include selection of primitives such as vertices, edges, or faces and performing translation, rotation, and scaling. Sculpting tools move many data points simultaneously, they are often used for defining organic surfaces now that modern machines are sufficiently powerful. Experienced artists might search for an existing base mesh that is similar to start on, but it is not always the case that such a base mesh exists - there are also concerns for quality, such as poor topology. As the geometry becomes more detailed and well-defined, each alteration makes less impact and the space of sensible changes becomes smaller. The design and production of 3D geometry remains a slow and delicate process.

Virtual hair creation is a necessity for characters of CG movies and video games that are embedded within culture both economically and as entertainment. Specialised artists learn to be proficient with the design of hair, variety of styles, and techniques for creating them. Hair geometry is much more concentrated than other types, containing many data points that is exhausting to edit. Soft selection and sculpting tools are good enough for defining the structure but maintaining topology and issues such as overlapping surfaces are still problematic. Learning the relation of hair structure allows the potential of discovering new hairstyles.  It can also be used as a mean of rapidly generating initial base geometry that fits the target output better than existing geometry available. Generative methods could ensure a level of quality, clean topology that fits established specifications. Assisted content generation using machine learning provides a convenient, non-intrusive and intuitive method for rapidly generating new hair geometry from existing data.

%**Move to evaluation
The application of machine-learning based tools could enhance the workflow of professional users and improve the experience for non-expert consumers. Such tools integrate into the production environment to improve the efficiency of acquiring initial base geometry and visually compare designs during pre-production. Non-expert users receive the ability to produce 3D geometry without requiring to learn the intrinsics of traditional 3D modelling software. The rise of augmented reality and 3D printing inspires the development of generative tools that are intuitive and simplistic to use. Applications that allow users to create personal content could also integrate machine-learning based tools to prevent inappropriate or undesirable creation from being produced while providing options that surpass existing alternatives. An example would be avatar creation for many applications and video games. A space of reasonable options generated from predefined outputs by the developers will allow users to interpolate between sensible configurations, providing an excellent level of customisation while adhering to defined constraints.

\section{Related Research of Machine Learning in Creative Fields}
The task of machine learning can be divided into three major paradigms: 
\begin{itemize}
	\item \textit{Supervised learning} is provided input training examples with desired outputs to learn the mapping of inputs to output.
	\item \textit{Unsupervised learning} is given only input data, the procedure learns structure of and relation between data.
	\item \textit{Reinforcement learning} seeks to iteratively improve a pool of solutions by simulating an environment that apply concepts inspired by the theory of evolution.
\end{itemize}
The role that learning methods play in both manufacturing and consumer application continue to grow, however, adoption has been slow for creative fields.  Generally, robust models improve in performance as more reliable data is obtained. Creative production values uniqueness and versatility, properties that cause difficulty in machine learning methods. Varying artistic styles in design complicate feature analysis and ambiguity of correctness is problematic when predicting an output.

To overcome the challenges of the scenario introduced above, unsupervised learning with probabilistic latent variable models such as the Gaussian Process Latent Variable Model \cite{gplvm} present an opportunity to learn stylistic properties of design and predict multiple acceptable outputs by analysing the likelihood.
Previous research conducted has explored the idea of applying machine learning in creative fields.

\subsection{Style-Based Inverse Kinematics}
Style-based inverse kinematics introduced the Scaled Gaussian Process Latent Variable Model, based on GPLVM, to learn the probabilistic distribution of a 3D human posture model. \cite{styleik} Character posing from motion data is represented as a 42-dimensional feature vector that encapsulated joint information of a humanoid body. Learning a model of poses established the relation between joints and identified constraints exhibited in the training data - where unusual postures are given a lower likelihood rating.

\subsection{Latent Doodle Space}
A latent doodle space is the use of a low-dimension latent space that has been applied on simple line drawings. \cite{latentdoodle} The motivation of a latent doodle space is to generating new drawings that are inspired by the input data. There are two key phases to derive a latent doodle space: the first challenge is to identify line strokes within drawings, a latent variable method is then used to learn a latent space.

\subsection{Learning a Manifold of Fonts}
A study by Campbell \& Kautz presented a framework that learns the latent manifold of existing font styles. \cite{fontmanifold} The process involved universal parametrization of fonts to a polyline representation so that a distance measure is applicable and the generative model can interpolate between styles. Unsupervised learning with the GP-LVM model enabled rapid prototyping and non-experts could create font styles without experience on type design.

\subsection{Real-time Drawing Assistance through Crowd-sourcing}
Drawing assistance powered by large-scale crowd-sourcing explored the potential of data driven drawing to prompt for correction by achieving an artistic consensus. \cite{drawingassistance} A consensus is found by learning a correction vector field from training drawings. Stroke-correction is applied using the correction vector field to adjust user input dynamically.

\subsection{AutoHair}
Chai, et al introduced AutoHair, a method for automatic modelling of 3D hair from a portrait image. \cite{autohair} The approach extracts information from images and uses a database of hair meshes to construct a 3D representation of the information conveyed. A hierarchical deep neural network trained on annotated hair images learn to segment hair and estimate growth direction within portraits. Data-driven hair matching and modelling algorithm fit meshes from the database to parameters output by the neural net model to automatically produce 3D hair. The experiment developed a traversable hairstyle space of 50,000 hair models, using training images and 3D exemplars obtained from the internet.

\section{Challenges}
This study faces a number of challenges. Firstly, 3D meshes are difficult to compare. The training data in its raw form will have varying dimensions. Meshes can be viewed as samples of the true geometry, thus meshes that represent the same object could differ drastically in number of data points depending on its level of detail. Typical feature extraction methods do not work well on meshes as artistic products are sensitive to data loss - any change could affect the perception of final result drastically.

Another problem encountered is the lack of training data. Typical machine learning solutions use huge data sets in the order of hundreds of thousands for training, but for 3D meshes the expected size of readily available training data is much smaller. Public repositories of 3D polygonal hair are generally around a few thousand in size. \cite{tsr} Studios that store and organise past production could likely match the size of public repositories, depending on the size of the company. Independent artists that keep their production will rarely go beyond the range of hundreds.

The application of machine learning methods must also account for subjectivity of evaluating artistic assets. The range of acceptable solutions is ambiguous, likened to how hair styles of characters can change drastically during the design phase, determining the threshold of acceptable solutions will be in itself a chaitllenge to resolve.

As mentioned previously, 3D meshes are delicate and can easily be invalidated from small changes. Thus, reparations to ensure that the output of trained models are acceptable is a topic to explore.

In a production environment, the time required for a technique to return observable result directly affects throughput. For practical efficacy of assisted content generation, the technique should be reasonably fast in presenting observable output.

\section{Central Objectives}
%The aim of this study is ...
\begin{itemize}
	\item Resolving the alignment problem of 3D data through a representative generative model.
	\item Explore the application of GP-LVM for 3D hair geometry in a production pipeline.
	\item Investigate the use of latent variables for identifying stylistic properties of 3D hair geometry.
	\item Demonstrate the use of non-linear manifold to generate new hairstyles from training data.
	\item Enable an intuitive method for non-experts to create 3D hair geometry.
	\item Observable output demand performance close to real-time for practical use.
\end{itemize}

% -----------------------------------------------------------------------------

\chapter{Technical Background}
\label{chap:technical}

\section{Principal Component Analysis}
In order to comprehend how GPLVM can learn a latent manifold from observed data, 
first we consider how it was derived, starting from principal component analysis.

In multivariate analysis, principal component analysis (PCA) is a statistical technique used to perform dimensionality reduction. It was originally introduced by Pearson \cite{pca1901}, and independently developed by Hotelling \cite{pca1933}, where the standard algebraic derivation of PCA was presented in terms of a standardized linear projection.

Consider the properties that define hair structure. Observable variables that can be measured include location, orientation, length, and colour. The data collected may indicate that some variables change together, this relation is measured as the covariance. The PCA technique searches for an ordered set of linear combination of the observed variables that retain maximal variance. Should two observed variables strongly covary linearly, then it is plausible to describe the data with a single variable instead. The more linearly the variables covary, the less data is lost from choosing a smaller set of principal components, thus effectively reducing dimensionality.

Given a set of $n$ observed $d$-dimensional data in matrix form, $\bm{X=[x_1,...,x_n]}^T$, the $q$ principal components $\bm{w_j}$, $j \in {1,...,q}$, are the orthonormal axes with maximal variance retained. The first principal component is a linear function $\bm{\alpha}^T_1\bm{X}$ that retains most variance of $\bm{X}$, where $\bm{\alpha} = [\alpha_{11}, \alpha_{12}, ..., \alpha_{1n}]$ is a vector of $n$ constants such that:
$$\bm{\alpha}^T_1\bm{X}=\alpha_{11}\bm{x_1}+\alpha_{12}\bm{x_2}+...+\alpha_{1n}\bm{x_n} = \sum^n_{i=1}a_{1i}\bm{x_i}$$
The following principal components are found by looking for a linear function that is orthogonal to the selected principal components and retain maximum variance.

PCA can be performed by singular value decomposition (SVD) of $\bm{X}$ in matrix form, \cite{pca2002}
$$\bm{X=ULV}^T,$$
where given $r = r(\bm{X})$ denotes the rank of $\bm{X}$, then
$\bm{U}$ is a $n \times r$ matrix of orthonormal columns that are the left singular vectors,
$\bm{L}$ is a $r \times r$ diagonal matrix of the singular values of $\bm{X}$, and
$\bm{V}$ is a $d \times r$ matrix of orthonormal columns that are the right singular vectors.
\section{Probabilistic Principal Component Analysis}
A limitation of standard PCA is the lack of a probabilistic solution. Tipping and Bishop introduced a probabilistic principal component analysis by constraining a latent variable model to be effectively equivalent when its marginal likelihood is maximised. \cite{ppca}

Suppose that the PCA is applied to a set of data that represents hair structure. Standard PCA searches for the orthonormal axes that retain maximal variance. Extrapolating values using the principal axes can infer new hairstyles, but only within a fixed style embedded by the axes. In the case of 3D content production, it is much more useful to have a selection of plausible designs to choose from. A probabilistic model of PCA will enable exploration of other potential linear embeddings of hair structure.


\subsection{The Gaussian Distribution}
The Gaussian (normal) distribution is a reasonable prior assumption for data that is subject to the central limit theorem, which states that as the sample size of a population tends to infinity, the distribution becomes increasingly Gaussian. \cite[p.78]{bishop}
A random variable $X$ that is normally distributed with mean $\mu$ and variance $\sigma^2$ is denoted as
$$X\sim\mathcal{N}(\mu, \sigma^2).$$
The Gaussian density for a single variable $y$ is expressed as \cite[p.78]{bishop}:
$$\mathcal{N}(y|\mu, \sigma^2)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(y-\mu)^2}{2\sigma^2}\right),$$
$$\mathcal{N}(y|\mu,\sigma^2) \equiv p(y|\mu,\sigma^2).$$

\subsubsection{Properties of Gaussian Distribution}
Notable properties of the Gaussian distribution that are useful include the summation (\ref{gd:sum}), scaling (\ref{gd:scale}), and product (\ref{gd:prod}) operation - all of which yields a result that is also a Gaussian distribution. \cite[p.200]{gp}
\begin{equation} \label{gd:sum}
\sum^n_{i=1}y_i\sim\mathcal{N}(\sum^n_{i=1}\mu_i,\sum^n_{i=1}\sigma^2_i)
\end{equation}

\begin{equation} \label{gd:scale}
wy\sim\mathcal{N}(w\mu,w^2\sigma^2)
\end{equation}

\begin{equation} \label{gd:prod}
\mathcal{N}(\bm{x|a},A)\mathcal{N}(\bm{x|b},B) = \mathcal{N}(\bm{a|b},A+B)\mathcal{N}(\bm{x}|\bm{c}, C),
\end{equation}
$$\bm{c}=C(A^{-1}\bm{a}+B^{-1}\bm{b}),$$
$$C = (A^{-1}+B^{-1})^{-1}).$$


\subsubsection{Multivariate Gaussian Distribution}
{\color{red} move to PPCA derivation? }

\noindent
Let $w$ and $h$ be jointly Gaussian distributed variables, if the variables are independent, then $p(w,h)=p(w)p(h)$.
The joint probability density is thus,
$$p(w,h)=\frac{1}{\sqrt{2\pi\sigma^2_1}\sqrt{2\pi\sigma^2_2}}\exp\left(-\frac{1}{2}\left(\frac{w-\mu_1)^2}{\sigma^2_1}+\frac{h-\mu_2)^2}{\sigma^2_2}\right)\right).$$
In matrix form, the joint probability is
$$p(w,h)=\frac{1}{2\pi\sqrt{\sigma^2_1\sigma^2_2}}\exp
\left(
-\frac{1}{2}
\left(
\left[
\begin{matrix}
w \\
h
\end{matrix}
\right]
-
\left[
\begin{matrix}
\mu_1 \\
\mu_2
\end{matrix}
\right]
\right)^T
\left[
\begin{matrix}
\sigma^2_1  &   0\\
0           &   \sigma^2_2
\end{matrix}
\right]
\left(
\left[
\begin{matrix}
w \\
h
\end{matrix}
\right]
-
\left[
\begin{matrix}
\mu_1 \\
\mu_2
\end{matrix}
\right]
\right)
\right).$$
For a $n$-dimensional vector $\bm{y}$, the joint probability density is expressed as
$$p(\bm{y})=\frac{1}{2\pi|\bm{D}|^{1/2}}\exp\left(-\frac{1}{2}(\bm{y}-\bm{\mu})^T\bm{D}^{-1}(\bm{y}-\bm{u})\right), \cite[p.78]{bishop}$$
where $\bm{D}\in\Re^{n \times 1}$ is the diagonal matrix of the variances $\Sigma$.
An arbitrary rotation matrix $\bm{R}^T\in\Re^{n \times n}$ applied to the basis forms a correlated Gaussian,
$$p(\bm{y})=\frac{1}{2\pi|\bm{D}|^{1/2}}\exp\left(-\frac{1}{2}(\bm{R}^T\bm{y}-\bm{R}^T\bm{\mu})^T\bm{D}^{-1}(\bm{R}^T\bm{y}-\bm{R}^T{u})\right).$$
This gives an eigenvalue decomposition of the inverse covariance matrix, 
$$\bm{C}^{-1}=\bm{RD}^{-1}\bm{R}^T,$$
thus the covariance matrix, 
$$\bm{C}=\bm{RDR}^T.$$

{\color{red}
As a consequence, if $\bm{x}\sim\mathcal{N}(\bm{\mu},\bm{\Sigma})$, and $\bm{y}=\bm{Wx}$, then $\bm{y}\sim\mathcal{N}(\bm{W\mu},\bm{W \Sigma W}^T)$.

Given
$\bm{x}\sim\mathcal{N}(\bm{0},\bm{I})$,
$\bm{\epsilon}\sim\mathcal{N}(\bm{0},\bm{\sigma}^2)$, and
$\bm{y}=\bm{Wx}+\bm{\epsilon}$, then
$\bm{Wx}\sim\mathcal{N}(\bm{0},\bm{WW}^T)$,
$\bm{y}\sim\mathcal{N}(\bm{0},bm{C})$, where $\bm{C}=\bm{WW}^T\beta^{-1}\bm{I}$, and $\bm{I}$ is the identity matrix. \cite{gplvm}




}

\subsection{Latent Variable Models and Factor Analysis}
A latent variable model transforms a set of $n$ $d$-dimensional observed variables encoded as a data matrix, $\bm{Y}^T\in\Re^{n \times d}$, to a set of $n$ $q$-dimensional latent (unobserved) variables, $\bm{X}\in\Re^{n \times q}$. Latent variables are parsimonious, it is generally the case that $q \ll d$, explaining the original data with fewer variables. A notable latent variable model is that of factor analysis, one that assumes linearity in relation of the observed data set,
\begin{equation} \label{ppca:fa}
\bm{Y=WX+\mu+\epsilon}.
\end{equation}
$\bm{W}$ represents a matrix that specifies the linear relation between the observed data-space with the latent-space.
The parameter $\mu$ allows for non-zero mean, and the $\epsilon$ parameter represents noise within the model. Standard PCA can be viewed as a variant of factor analysis where the noise parameter is not accounted for. The maximum-likelihood estimates of $\bm{W}$ will thus generally not correspond to the principal subspace. Tipping and Bishop develop a latent variable model that performs principal component analysis by modelling the parameter $\epsilon$ of equation \ref{ppca:fa} as an isotropic, spherical Gaussian distribution $\mathcal{N}(\bm{0},\beta^{-1}\bm{I})$. The conditional probability distribution is thus,
\begin{equation} \label{ppca:conditional}
p(\bm{Y|X})=\mathcal{N}(\bm{WX+\mu},\beta^{-1}\bm{I}). 
\end{equation}
The marginal distribution over the latent variables are standard Gaussian, defined as $\bm{X\sim\mathcal{N}(0,I)}$. The marginal distribution for the observed data $\bm{Y}$ is obtained by integrating out the latent variables,
$$\bm{Y}\sim\mathcal{N}\bm{(\mu,C)}.$$
The observation covariance model is $\bm{C=WW}^T+\beta^{-1}\bm{I}$, and corresponding log-likelihood
\begin{equation} \label{ppca:loglikelihood}
\mathcal{L}=\frac{n}{2}(d ln(2\pi)+ln|\bm{C}|+tr(\bm{C^{-1}S})),
\end{equation}
$$\bm{S}=\frac{1}{n}\sum^n_{i=1}(\bm{y}_i-\mu)(\bm{y}_i-\mu)^T$$

\subsection{A Probabilistic Model for PCA}
Consider a data matrix of $n$ centred $d$-dimensional vectors $\bm{Y=[y_1,...,y_n]}^T$.
For each observed data point, $1 \leq i \leq n $, there is an associated $q$-dimensional latent variable $\bm{x_i}$.

The original data can be represented in terms of the latent variable with noise value,
$$\bm{y_i=Wx_i+\epsilon_i}.$$
The matrix $\bm{W \in \Re^{d \times q}}$ represents the linear relationship between the latent-space with the  data-space. The noise values, $\epsilon_i \in \Re^{d \times 1}$, are sampled from a independent spherical Gaussian distribution, $\epsilon_i\sim\mathcal{N}(\bm{0, \beta^{-1}I})$.

{ \color{red}
	By the product property of Gaussian distribution, the likelihood of a data point is thus
}
\begin{equation} \label{ppca:likelihood}
p(\bm{y_i|x_i,W,\beta)=\mathcal{N}(y_i|Wx_i,\beta^{-1}I)}.
\end{equation}
Integrating over the latent variables gives the marginal likelihood,
$$p(\bm{y_i|W,\beta})=\int p(\bm{y_i|x_i,W,\beta})p(\bm{x_i})d\bm{x_i}.$$
As the prior of probabilistic PCA is modelled as a standard Gaussian distribution, $p(\bm{x_i})=\mathcal{N}(\bm{x_i|0,I})$,
marginalisation of the integral obtains the marginal likelihood of each data point as
$$p(\bm{y_i|W,\beta})=\mathcal{N}(\bm{y_i|0,WW^T+\beta^{-1}I}).$$
Assuming that the data points are independent, the likelihood of the full data set is the product of each marginal likelihood,
$$p(\bm{Y|W,\beta})=\prod^n_{i=1} p(\bm{y_i|W,\beta}).$$

\subsection{The Principal Subspace of PPCA}
Tipping and Bishop\cite{ppca} showed that all potential solutions for $\bm{W}$, the likelihood (\ref{ppca:loglikelihood}), is of the form $$\bm{W=U_q(K_q-\sigma^2I)^\frac{1}{2}R}.$$
One particular case of interest is when the likelihood is maximised,
\begin{equation} \label{ppca:ml}
\bm{W}_{ML}=\bm{U}_q\bm{LR},
\end{equation}
$$\bm{L}=(\Lambda_q-\sigma^2\bm{I})^{\frac{1}{2}}$$
The matrix $\bm{U_q}\in\Re^{d \times q}$ contains the column vectors that are the principal eigenvectors, $\Lambda_q=[\lambda_1,...,\lambda_q]$ represents the diagonal matrix of the corresponding eigenvalues, and $\bm{R}\in\Re^{q \times q}$ represent an arbitrary orthogonal rotation matrix. 

Maximising the likelihood of $\bm{W}$ by equation \ref{ppca:ml} on the latent variable model defined by equation \ref{ppca:fa} maps the latent-space to the principal subspace of the observed data. Selecting $\bm{W}_{ML}$, the latent variable model is effectively equivalent to standard principal component analysis.

\section{Gaussian Process Latent Variable Model}
The Gaussian Process Latent Variable Model (GP-LVM) is a non-linear latent variable model derived from a dual of the probabilistic PCA by replacing the inner product kernel with Gaussian processes (Lawrence 2005) \cite{gplvm}. The use of an inner product kernel that allows for non-linear functions enable a non-linear embedding of the data-space to obtain a lower dimension latent-space. 

{\color{red}
	PPCA presents a space of linearly embedded hairstyles, however, it is unlikely that linear embeddings of observed variables for hair is effective for high dimensional data such as hair structure. GP-LVM replaces the covariance matrix with a non-linear kernel, allowing non-linear embedding of the observed variables to capture the complexity of hair structure.
}

\subsection{Dual Probabilistic PCA}
The dual probabilistic PCA introduced by Lawrence marginalises the parameters, $\bm{W}$, and optimises with respect to latent variables, $\bm{X}$. This is the dual approach of the standard probabilistic PCA where the parameters are optimised and the latent variables are marginalised.

First, a conjugate prior to the likelihood of probabilistic PCA (\ref{ppca:likelihood}) is taken to be a spherical Gaussian distribution,
$$p(\bm{W})=\prod^d_{i=1}\mathcal{N}(\bm{w}_i|\bm{0,I}).$$
As marginalisation of both $\bm{W}$ and $\bm{X}$ is intractable, $\bm{W}$ is selected for marginalisation as the conjugate prior is Gaussian distributed, thus, it can be integrated analytically.
The marginalised likelihood of $\bm{W}$ is
$$p(\bm{Y|X},\beta)=\prod^d_{i=1}p(\bm{y}_{:,i}|\bm{X},\beta),$$
The $\bm{y}_{:,i}$ parameter represents the $i^{it}$ column of $\bm{Y}$, where
$$p(\bm{y}_{:,i}|\bm{X},\beta)=\mathcal{N}(\bm{y}_{:,i}|\bm{0,XX}^T+\beta^{-1}\bm{I}).$$
The objective function is the log-likelihood
\begin{equation} \label{dppca:loglikelihood}
L=-\frac{dn}{2}ln2\pi-\frac{d}{2}ln|\bm{K}|-\frac{1}{2}tr(\bm{K^{-1}YY}^T),
\end{equation}
$$\bm{K=XX}^T+\beta^{-1}I.$$
In the original paper, Lawrence found the gradients of the log-likelihood (\ref{dppca:loglikelihood}) with respect to $\bm{X}$ as
$$\frac{\sigma L}{\sigma \bm{X}}=\bm{K^{-1}YY}^T\bm{K^{-1}X}-d\bm{K^{-1}X}.$$ 
A stationary point where the gradients are zero is given by
$$\frac{1}{d}\bm{YY}^T\bm{K^{-1}X=X}.$$
The values for $\bm{X}$ which maximise the likelihood are given by singular value decomposition of $\bm{X}$,
$$\bm{X=ULV}^T.$$
$\bm{U}$ is an $n \times q$ matrix whose orthonormal column vectors are the first eigenvectors of $\bm{YY}^T$. $\bm{L}$ is a $q \times q$ diagonal matrix of singular values, whose $j^{th}$ element is $l_j=(\lambda_j-\frac{1}{\beta})^{-\frac{1}{2}}$, where $\lambda_j$ is the eigenvalue associated with the $j^{th}$ eigenvector $d^{-1}\bm{YY}^T$. $\bm{V}$ is an arbitrary $q\times q$ rotation matrix. Lawrence showed that the eigenvalue problem developed here is equivalent to the eigenvalue problem solved in PPCA, and thus, DPPCA is also effectively equal to standard PCA when the likelihood is maximised.

Dual probabilistic PCA assumes that the output dimensions are linear, independent, and identically distributed. Infringing upon these assumptions derive new probabilistic models.

\subsection{Gaussian Processes}
{\color{red}
	(O'Hagan, 1992; Williams, 1998)
	
	Gaussian processes are a class of probabilistic models that generalizes a Gaussian probability distribution. The Gaussian process approximates a distribution function in a space of infinite values to a finite range that is tractable.
	
	A Gaussian process first requires specifying a prior, parametrised by a mean and covariance.
	A simple prior over the space of functions that are linear but corrupted by Gaussian noise of variance $\beta^{-1}\bm{I}$ is
	\begin{equation} \label{gp:prior}
	k(\bm{x}_i,\bm{x}_j)=\bm{x}^T_i\bm{x}_j+\beta^{-1}\delta_{ij}.
	\end{equation}
	$\bm{x}_i$ and $\bm{x}_j$ are vectors from the space of inputs to the function and $\sigma_1{ij}$ is the Knronecker delta. If these inputs were taken from our embedding matrix, $\bm{X}$, and the covariance function was evaluated at each of the $N$ points, we would recover the covariance matrix of the form
	$$\bm{K=XX}^T+\beta^{-1}\bm{I}$$
	where the element at $ith$ row and $jth$ column of $\bm{K}$ is given by the prior (\ref{gp:prior}). This is recognised as the covariance associated with each factor of the marginal likelihood for dual probabilistic PCA. The marginal likelihood for dual probabilistic PCA is therefore a product of $d$ independent Gaussian processes. In PCA we are optimising parameters and input positions of a Gaussian process prior distribution where the (linear) covariance function for each dimension is given by $\bm{K}$.
	
	**Explain better \& kernels
}



\section{Bayesian Gaussian Process Latent Variable Model}
The Bayesian Gaussian Process Latent Variable Model (Bayesian GP-LVM) \cite{bgplvm} extends the GP-LVM by variationally integrating out the input variables of the Gaussian process to approximate the marginal likelihood of a fully marginalised model. The approximated marginal likelihood can be used to compute a lower bound that is robust to overfitting. A fully marginalised model establishes a Bayesian perspective that copes well with uncertainty caused by missing data and can automatically determine latent dimensions within the observed data set.

The marginalised likelihood of the GPLVM can be represented in the form
$$p(\bm{Y|X})=\prod^d_{i=1}p(\bm{y}_{:,i}|\bm{X})$$
where $\bm{y}_{:,i}$ represents the $i^{th}$ column of $\bm{Y}$ and
$$p(\bm{y}_{:,i}|\bm{X})=\mathcal{N}(\bm{y_{:,i}|0},K_{nn}+\beta^{-1}\bm{I}_n).$$
$K_{nn}$ is the $n \times n$ covariance matrix defined by the kernel function $k(\bm{x,x'})$.
The latent variable X is assigned a prior density given by the standard Gaussian distribution, 
$$p(\bm{X})=\prod^n_{i=1}\mathcal{N}(\bm{x_i|0, I_Q}).$$
Each $\bm{x_i}$ is the $i^{th}$ row of $\bm{X}$. The joint probability model for the GP-LVM is
$$p(\bm{Y,X})=p(\bm{Y|X})p(\bm{X})$$

The standard GP-LVM method trains by finding the MAP estimate of $\bm{X}$ whilst jointly maximizing with respect to the hyperparameters. Bayesian GP-LVM performs variational inference to marginalise the latent variables. This method enables optimisation of the resulting lower bound on the marginal likelihood with respect to the hyperparameters. 

\subsection{Variational Inference}
{ \color{red}In order to apply variational Bayesian methods to GP-LVM, the latent/input variables that appear non-linearly must first be approximately integrated out.}

The marginal likelihood of the observed data is obtained by integrating out the latent variables:
$$p(\bm{Y})=\int p(\bm{Y|X})p(\bm{X})d\bm{X}.$$
Computationally, this integration is intractable in practice. Variaitonal Bayesian methods can instead be used by using variational distribution $q(\bm{X})$ to approximate the posterior distribution over the latent variables, $p(\bm{X|Y})$.
$$q(\bm{X})=\prod^n_{i=1}\mathcal{N}(\bm{x_n|\mu_n,S_n}).$$
The variational parameters are $\bm{ \{ \mu_n,S_n \}^n_{i=1} }$ and $\bm{S_n}$ is a diagonal covariance matrix. 

The variational distribution can then be used to obtain a Jensen's lower bound on $\log p(\bm{Y})$:
$$F(q)=\int q(\bm{X})\log \frac{ p(\bm{Y|X})p(\bm{X}) }{ q(\bm{X}) } d\bm{X}$$
$$=\int q(\bm{X})\log p(\bm{Y|X})p(\bm{X})d\bm{X} - \int q(x)\log\frac{q(X)}{p(X)}dX$$
$$=\tilde{F}(q)-KL(q||p).$$
The $KL(q||p)$ term is the negative KL divergence between the variational posterior distribution $q(X)$ and the prior distribution p(X) over the latent variables. Since the distributions are Gaussian, the negative KL divergence is tractable. The problematic term is $\tilde{F}(q)$, where variational sparse Gaussian process regression is applied for approximation.

\section{Formal Definition of 3D Polygon Mesh Representation}
%\cite{polyhedron}The winged-edge polyhedron representation proposed by Baumgart in 1972 introduced a mesh data structure to represent 3D geometry using vertices, edges, and faces. \cite{wingededge}

Polygon mesh representation of 3D surfaces are composed of vertices, edges, and faces. Let polygon mesh $P = (\bm{V, E, F})$, where $\bm{V, E, F}$ represents the set of vertices, edges, and faces respectively. In practice, polygonal meshes contain more components that affect surface appearance such as texture coordinates and vertex normals, however, the components described are sufficient for geometric processing.

\subsection{Mesh Vertices}
A mesh vertex $v$ is a 3D point of the form $\forall (x, y, z) \in \Re, v = (x, y, z)$.
The set of vertices is a point cloud representation of the geometry. 

\subsection{Edges}
An edge $e$ is an unordered pair that connects two vertices. Formally, it is described in the form $\forall (v_1, v_2) \in \bm{V}, e = \{v_1, v_2\}$. Vertices connected by edges form a wireframe of the geometry. 

\subsection{Polygon Faces}
A polygon face can be formed from an arbitrary number of vertices $\forall (v_1, v_2,...,v_n) \in \bm{V}, f_n = (v_1, v_2,..., v_n)$, however, in this context we are only concerned with tri-faces $\forall (v_1, v_2, v_3) \in \bm{V}, f_3 = (v_1, v_2, v_3)$ and quad-faces $\forall (v_1, v_2, v_3, v_4) \in \bm{V}, f_4 = (v_1, v_2, v_3, v_4)$. Faces describe the geometric surface of an object. 

\subsection{Edge Loops}
{\color{red}
	3D programs often allow edge loop selection which are useful properties of the geometry. An edge loop is defined (on blender) as a set of connected edges that either forms a loop or the end vertices are poles (vertices that do not have edges). Edge loops are useful for extracting more information on the structure of the mesh.
	\cite{edgeloops}
}

\subsection{Topology}
Tris, quads, poles, etc

\section{Graph Theory}
The construction of 3D polygonal meshes resemble graphs very much. As it turns out, methods of graph theory are useful for processing meshes.




% -----------------------------------------------------------------------------

\chapter{Project Execution}
\label{chap:execution}

\section{Training Data Set}
\subsection{Acquiring Training Data}
To begin the training process, it is necessary to obtain suitable 3D hair geometry for use as input training data. Compared to the abundance of images freely available, appropriate 3D models are much less common. Courtesy of Electronic Arts, there exists an active community that produces free custom content for their gaming software - which includes polygonal hair. \cite{tsr} The acquired files are encoded in the \textit{PACKAGE} format for the latest game of \textit{The Sims} franchise. Open-source community software \textit{s4pe} is used to read the package file and extract geometry in \textit{SIMGEOM} format. \cite{s4pe} The \textit{SIMGEOM} format is then converted to \textit{OBJ} format using yet another open-source program \textit{S4CASTools}. \cite{s4cas} The geometry extracted is already standardised in scale and orientation.

\subsection{Repairing Training Data}
As mentioned, it is often the case for 3D mesh topology to be organised by quad-faces. In video games, quad-faced meshes are converted to triangle-faced before the rendering pipeline. Mesh reconstruction is performed on all input data to convert the geometry from triangle-face meshes to quad-faces. The Blender API offers a tool to automate this process, executed by the following algorithm:

\begin{algorithm}[!h]
	\caption{Tri-to-quad using Blender API}
	\For{$i=0$ {\bf upto} $n$}{
		$t_i \leftarrow 0$\;
	}
\end{algorithm}

Current solutions for converting a triangle meshes to a quad mesh is imperfect. After the procedure, the remaining triangle faces are converted manually. The conversion process alters the geometry very marginally, but the hair representation is preserved - the quad-faced meshes are used for training, and are assumed to be correct in the context that it representative of a valid hairstyle.

\section{Generative Model of Hair}
A generative model is developed for the purpose of approximating the raw data and output generation. Mesh data is difficult to compare as topology and fidelity alters both structure and dimensionality. In order to resolve the data alignment problem, the mesh is approximated to generative parameters of the closest output possible in the generative model. Learning is trained using these generative parameters obtained from approximating the mesh data. 

Spherical coordinates
Sphere Reference
Sample X*Y roots uniformly on surface of sphere
From these roots, grow Z points to form strand splines

\begin{lstlisting}[float={!h},caption={Generative Hair Parameter Format.},label={aa},language=C]
[[0.0,0.0,0.0]]
\end{lstlisting}

\section{Approximating Generative Parameters from Input Data}
\subsection{Parsing OBJ File}
Mesh geometry data of \textit{OBJ} files are read into a graph data structure of nodes and edges. Each vertex read swaps the Y and Z axis and the Y axis is negated to align the coordinate space used by Blender and \textit{OBJ} format.

\begin{algorithm}[!h]
	\For{$i=0$ {\bf upto} $n$}{
		$t_i \leftarrow 0$\;
	}
	\caption{Parsing OBJ format.}
	\label{alg}
\end{algorithm}

\subsection{Spline Estimation}
Hair structure estimation begins by splitting the hair mesh into sub-meshes of hair segments determined by connectivity. For each segment, its border edge loops are extracted by finding corner vertices (having exactly two neighbour vertices). A root border edge loop is determined by finding the border edge that is closest to the root. Using the root border edge loop, spline edge loops are selected as strands of hair.

A repair operator performs reparation on extracted splines: attaching floating splines to closest ends of root splines. Splines that are too short are also removed.

\subsection{Structure Estimation}
Each root is associated to a spline by a selection operator. Attributes that make a spline more desirable to a particular root are attributes such as proximity or uniqueness compared to previously selected splines. The motivation is to use a set amount of roots to represent the hair structure without losing too much information.

\section{Learning a Manifold with Bayesian GP-LVM}
Add offset so top of head is "mean", so uncertain hair moves towards the top (avoids hair moving inside head or other unlikely areas)
Training with GPLVM.
Kernel used.
Give algorithm.

\section{Generation of Output}
GPy native matplotlib conflicts with Blender as TKInter is disabled.
Plot image of latent space to be imported into image editor of Blender.
Pickle model to be imported by Blender's python.
Select latent variables from manifold (Blender event API)
Read model and predict output by selected latent variables
Generate guide splines following format of latent model and generative model
Extrude by spline object
Rotate by head surface normals
Convert to Poly

\section{Reparation}
Normals, clusters, intersections

\section{Project Management}
\subsection{Source Control}
Git is used for source control of the project implementation. The branching feature is useful for separating development of features. Maintaining multiple versions of the code base prevented issues caused by the interaction of incomplete features. The merging and rebasing tools helped conflict resolution. Descriptive atomic commits keep a log of progress and supports roll-back to older versions when necessary. A private repository backup was set up on a hosting service provider to prevent data loss and enable development on multiple machines with ease.

\subsection{Issue Tracking}
Trello

\subsection{Time-line}
Calender.
Internal Deadlines.

\begin{table}[!h]
	\centering
	\begin{tabular}{|cc|c|}
		\hline
		foo      & bar      & baz      \\
		\hline
		$0     $ & $0     $ & $0     $ \\
		\hline
	\end{tabular}
	\caption{This is an example table.}
	\label{tab}
\end{table}

% -----------------------------------------------------------------------------

\chapter{Critical Evaluation}
\label{chap:evaluation}

\section{Functional Testing}
functional  testing, including analysis and explanation of failure cases.
5 pages

\section{Behavioural Testing}
behavioural testing, often including analysis of any results that draw some form of conclusion wrt. the aims and objectives
5 pages

\section{Evaluation}
evaluation of options and decisions within the project, and/or a comparison with alternatives.
2 page

\section{Applications}
MMOs, games, etc
1 page

% -----------------------------------------------------------------------------

\chapter{Conclusion}
\label{chap:conclusion}

\section{Summary}
(Re)summarise the main contributions and achievements, in essence
summing up the content. 2 pages

\section{Project Status}
Clearly state the current project status (e.g., ``X is working, Y 
is not'') and evaluate what has been achieved with respect to the 
initial aims and objectives (e.g., ``I completed aim X outlined 
previously, the evidence for this is within Chapter Y'').  There 
is no problem including aims which were not completed, but it is 
important to evaluate and/or justify why this is the case. 2 pages

\section{Future Work}
Outline any open problems or future plans.  Rather than treat this
only as an exercise in what you {\em could} have done given more 
time, try to focus on any unexplored options or interesting outcomes
(e.g., ``my experiment for X gave counter-intuitive results, this 
could be because Y and would form an interesting area for further 
study'' or ``users found feature Z of my software difficult to use,
which is obvious in hindsight but not during at design stage; to 
resolve this, I could clearly apply the technique of Smith [7]''). 1 page



% =============================================================================

% Finally, after the main matter, the back matter is specified.  This is
% typically populated with just the bibliography.  LaTeX deals with these
% in one of two ways, namely
%
% - inline, which roughly means the author specifies entries using the 
%   \bibitem macro and typesets them manually, or
% - using BiBTeX, which means entries are contained in a separate file
%   (which is essentially a databased) then inported; this is the 
%   approach used below, with the databased being dissertation.bib.
%
% Either way, the each entry has a key (or identifier) which can be used
% in the main matter to cite it, e.g., \cite{X}, \cite[Chapter 2}{Y}.

\backmatter

\bibliography{dissertation}

% -----------------------------------------------------------------------------

% The dissertation concludes with a set of (optional) appendicies; these are 
% the same as chapters in a sense, but once signaled as being appendicies via
% the associated macro, LaTeX manages them appropriatly.

\appendix

\chapter{An Example Appendix}
\label{appx:example}

Content which is not central to, but may enhance the dissertation can be 
included in one or more appendices; examples include, but are not limited
to

\begin{itemize}
	\item lengthy mathematical proofs, numerical or graphical results which 
	are summarised in the main body,
	\item sample or example calculations, 
	and
	\item results of user studies or questionnaires.
\end{itemize}

\noindent
Note that in line with most research conferences, the marking panel is not
obliged to read such appendices.

% =============================================================================

\end{document}
